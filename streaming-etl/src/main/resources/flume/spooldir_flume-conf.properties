# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


# The configuration file needs to define the sources, 
# the channels and the sinks.
# Sources, channels and sinks are defined per agent, 
# in this case called 'agent'

agent1.sources = spooldir_src
agent1.channels = memoryChannel
agent1.sinks = hdfs_sink

# For each one of the sources, the type is defined
agent1.sources.spooldir_src.type = spooldir
agent1.sources.spooldir_src.spoolDir = /root/dw-course/streaming-etl/logs/minute/bak
agent1.sources.spooldir_src.fileHeader = true
agent1.sources.spooldir_src.fileHeaderKey = file
agent1.sources.spooldir_src.basenameHeader = true
agent1.sources.spooldir_src.basenameHeaderKey  = basename

# The channel can be defined as follows.
agent1.sources.spooldir_src.channels = memoryChannel

# Each sink's type must be defined
agent1.sinks.hdfs_sink.type = hdfs
agent1.sinks.hdfs_sink.hdfs.path = hdfs://starl:9000/user/dw-course/user-action-minute
agent1.sinks.hdfs_sink.hdfs.useLocalTimeStamp = true 
# 上面匹配时间的话，需要打开这个开关，这个配置默认是false

agent1.sinks.hdfs_sink.hdfs.round = true
agent1.sinks.hdfs_sink.hdfs.roundValue = 10
agent1.sinks.hdfs_sink.hdfs.roundUnit = minute
# For example, an event with timestamp 11:54:34 AM, June 12, 2012 will cause the hdfs path to become /flume/events/2012-06-12/1150/00.

agent1.sinks.hdfs_sink.hdfs.filePrefix = events 
# 表示文件名的前缀，默认为FlumeData

agent1.sinks.hdfs_sink.hdfs.fileSuffix = .txt 
# 表示文件名的后缀，默认没有后缀

agent1.sinks.hdfs_sink.hdfs.idleTimeout = 0 
# 如果临时文件在这个时间内没有写数据的话，则将这个文件关闭掉，默认等于0，表示不关闭闲文件

agent1.sinks.hdfs_sink.hdfs.batchSize = 100 
# 表示数据每次flush到hdfs的event数，默认就是100

agent1.sinks.hdfs_sink.hdfs.inUsePrefix = events-tmp 
# 表示写临时文件的文件名的前缀，默认没有值

agent1.sinks.hdfs_sink.hdfs.inUseSuffix = .tmp 
# 表示写临时文件的文件名的后缀，默认就是.tmp

agent1.sinks.hdfs_sink.hdfs.rollInterval =30 
# 表示达到了30秒就将临时文件合并成最终文件，默认就是30秒，如果是0的话则表示不按照时间的多少来合并临时文件

agent1.sinks.hdfs_sink.hdfs.rollSize =0 
# 表示文件的大小达到了1024 bytes，则将临时文件合并成最终文件，默认就是1024字节，如0则表示不按照文件大小合并

agent1.sinks.hdfs_sink.hdfs.rollCount =0 
# 表示写入event的数量达到10条的话，则将临时文件合并成最终文件，默认就是10条，如0则表示不按照文件大小合并

agent1.sinks.hdfs_sink.hdfs.fileType = DataStream  
# 表示没有压缩的text文件，默认是SequenceFile，还有CompressedStream表示压缩的文本文件，需要设置hdfs.codeC

# agent1.sinks.hdfs_sink.hdfs.codeC = snappy 
# 可以为：gzip, bzip2, lzo, lzop

#Specify the channel the sink should use
agent1.sinks.hdfs_sink.channel = memoryChannel

# Each channel's type is defined.
agent1.channels.memoryChannel.type = memory

# Other config values specific to each type of channel(sink or source)
# can be defined as well
# In this case, it specifies the capacity of the memory channel
agent1.channels.memoryChannel.capacity = 100
