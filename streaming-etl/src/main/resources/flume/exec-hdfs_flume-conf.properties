# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


# The configuration file needs to define the sources, 
# the channels and the sinks.
# Sources, channels and sinks are defined per agent, 
# in this case called 'agent'

agent1.sources = user_action_log_src
agent1.channels = memoryChannel
agent1.sinks = hdfs_sink

# For each one of the sources, the type is defined
agent1.sources.user_action_log_src.type = exec
agent1.sources.user_action_log_src.command = tail -fn0 /root/dw-course/streaming-etl/logs/user-action.log
# 可以指定用什么样的shell来执行命令脚
#agent1.sources.user_action_log_src.shell = /bin/bash -c
#agent1.sources.user_action_log_src.command = for i in /path/*.txt; do cat $i; done
# 表示当cmd挂掉的时候，是否需要重启cmd， 默认是false
agent1.sources.user_action_log_src.restart = true
# 重启之前需要等待的时间长度，默认是10000毫秒
agent1.sources.user_action_log_src.restartThrottle = 10000
# 表示一次性批量的将多少条event发送channel， 默认是20条
agent1.sources.user_action_log_src.batchSize = 20
# 如果等待了3000毫秒，还没有达到上面配置的batchSize,则将所有的event发往channel
agent1.sources.user_action_log_src.batchTimeout = 3000

# 给user_action_log_src这个source指定channel
agent1.sources.user_action_log_src.channels = memoryChannel

# Each sink's type must be defined
agent1.sinks.hdfs_sink.type = hdfs
agent1.sinks.hdfs_sink.hdfs.path = hdfs://starl:9000/user/dw-course/user-action-allfile/%y-%m-%d/%H%M/%S
# 上面匹配时间的话，需要打开这个开关，这个配置默认是false
agent1.sinks.hdfs_sink.hdfs.useLocalTimeStamp = true
# For example, an event with timestamp 11:54:34 AM, June 12, 2012 will cause
# the hdfs path to become /flume/events/2012-06-12/1150/00.
agent1.sinks.hdfs_sink.hdfs.round = true
agent1.sinks.hdfs_sink.hdfs.roundValue = 10
agent1.sinks.hdfs_sink.hdfs.roundUnit = minute
# 表示文件名的前缀，默认为FlumeData
agent1.sinks.hdfs_sink.hdfs.filePrefix = events
# 表示文件名的后缀，默认没有后缀
agent1.sinks.hdfs_sink.hdfs.fileSuffix = .txt
# 表示写临时文件的文件名的前缀，默认没有值
agent1.sinks.hdfs_sink.hdfs.inUsePrefix = events-tmp
# 表示写临时文件的文件名的后缀，默认就是.tmp
agent1.sinks.hdfs_sink.hdfs.inUseSuffix = .tmp
# 表示数据每次flush到hdfs的event数，默认就是100
agent1.sinks.hdfs_sink.hdfs.batchSize = 100
# 表示达到了30秒就将临时文件合并成最终文件，默认就是30秒，如果是0的话则表示不按照时间的多少来合并临时文件
agent1.sinks.hdfs_sink.hdfs.rollInterval =30
# 表示文件的大小达到了1024 bytes，则将临时文件合并成最终文件，默认就是1024字节，如0则表示不按照文件大小合并
agent1.sinks.hdfs_sink.hdfs.rollSize =1024
# 表示写入event的数量达到10条的话，则将临时文件合并成最终文件，默认就是10条，如0则表示不按照event条数合并
agent1.sinks.hdfs_sink.hdfs.rollCount =10
# 如果临时文件在这个时间内没有写数据的话，则将这个文件关闭掉，默认等于0，表示不关闭闲文件
agent1.sinks.hdfs_sink.hdfs.idleTimeout = 0
# 表示没有压缩的text文件，默认是SequenceFile，还有CompressedStream表示压缩的文本文件，需要设置hdfs.codeC
agent1.sinks.hdfs_sink.hdfs.fileType = DataStream
# agent1.sinks.hdfs_sink.hdfs.codeC = snappy
# 可以为：gzip, bzip2, lzo, lzop

# 给hdfs_sink这个sink指定channel
agent1.sinks.hdfs_sink.channel = memoryChannel

# 定义channel
agent1.channels.memoryChannel.type = memory
#  这个内存channel中最多能存储的event的数量为100，默认为100
agent1.channels.memoryChannel.capacity = 100
